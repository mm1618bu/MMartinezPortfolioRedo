name: Automated Backups

on:
  # Run daily at 2 AM UTC
  schedule:
    - cron: '0 2 * * *'
  
  # Allow manual trigger
  workflow_dispatch:
    inputs:
      backup_type:
        description: 'Type of backup to run'
        required: true
        default: 'database'
        type: choice
        options:
          - database
          - storage
          - complete

jobs:
  backup-database:
    name: Database Backup
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event.inputs.backup_type == 'database' || github.event.inputs.backup_type == 'complete'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
      
      - name: Install PostgreSQL client
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client
      
      - name: Configure environment
        env:
          SUPABASE_DB_PASSWORD: ${{ secrets.SUPABASE_DB_PASSWORD }}
          REACT_APP_SUPABASE_URL: ${{ secrets.REACT_APP_SUPABASE_URL }}
          REACT_APP_SUPABASE_ANON_KEY: ${{ secrets.REACT_APP_SUPABASE_ANON_KEY }}
        run: |
          echo "SUPABASE_DB_PASSWORD=$SUPABASE_DB_PASSWORD" >> .env
          echo "REACT_APP_SUPABASE_URL=$REACT_APP_SUPABASE_URL" >> .env
          echo "REACT_APP_SUPABASE_ANON_KEY=$REACT_APP_SUPABASE_ANON_KEY" >> .env
      
      - name: Run database backup
        run: |
          chmod +x scripts/backup-database.sh
          ./scripts/backup-database.sh
      
      - name: Upload backup to artifacts
        uses: actions/upload-artifact@v4
        with:
          name: database-backup-${{ github.run_number }}
          path: backups/database/*.gz
          retention-days: 30
      
      - name: Upload to S3 (optional)
        if: env.AWS_ACCESS_KEY_ID != ''
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: us-east-1
          S3_BUCKET: youtube-clone-backups
        run: |
          aws s3 sync backups/database/ s3://$S3_BUCKET/database/ \
            --exclude "*" \
            --include "*.gz" \
            --storage-class STANDARD_IA

  backup-storage:
    name: Storage Backup
    runs-on: ubuntu-latest
    if: github.event.inputs.backup_type == 'storage' || github.event.inputs.backup_type == 'complete'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
      
      - name: Install Supabase CLI
        run: |
          npm install -g supabase
      
      - name: Configure environment
        env:
          REACT_APP_SUPABASE_URL: ${{ secrets.REACT_APP_SUPABASE_URL }}
          REACT_APP_SUPABASE_ANON_KEY: ${{ secrets.REACT_APP_SUPABASE_ANON_KEY }}
          SUPABASE_ACCESS_TOKEN: ${{ secrets.SUPABASE_ACCESS_TOKEN }}
        run: |
          echo "REACT_APP_SUPABASE_URL=$REACT_APP_SUPABASE_URL" >> .env
          echo "REACT_APP_SUPABASE_ANON_KEY=$REACT_APP_SUPABASE_ANON_KEY" >> .env
          supabase login --token $SUPABASE_ACCESS_TOKEN
      
      - name: Run storage backup
        run: |
          chmod +x scripts/backup-storage.sh
          ./scripts/backup-storage.sh
      
      - name: Upload backup to artifacts
        uses: actions/upload-artifact@v4
        with:
          name: storage-backup-${{ github.run_number }}
          path: backups/storage/**/*.tar.gz
          retention-days: 30

  verify-backups:
    name: Verify Backups
    runs-on: ubuntu-latest
    needs: [backup-database]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Download database backup
        uses: actions/download-artifact@v4
        with:
          name: database-backup-${{ github.run_number }}
          path: backups/database/
      
      - name: Run verification
        run: |
          chmod +x scripts/verify-backup.sh
          ./scripts/verify-backup.sh
      
      - name: Send notification on failure
        if: failure()
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.gmail.com
          server_port: 587
          username: ${{ secrets.EMAIL_USERNAME }}
          password: ${{ secrets.EMAIL_PASSWORD }}
          subject: 'ALERT: Backup Verification Failed'
          body: |
            Backup verification failed for YouTube Clone.
            
            Run: ${{ github.run_number }}
            Workflow: ${{ github.workflow }}
            Repository: ${{ github.repository }}
            
            Please investigate immediately.
          to: admin@example.com
          from: GitHub Actions

  cleanup-old-backups:
    name: Cleanup Old Backups
    runs-on: ubuntu-latest
    needs: [verify-backups]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Remove old artifacts
        run: |
          # Artifacts are automatically cleaned up after retention period
          # This is a placeholder for additional cleanup logic
          echo "Old backups will be cleaned up automatically after retention period"
      
      - name: Cleanup S3 old backups (optional)
        if: env.AWS_ACCESS_KEY_ID != ''
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: us-east-1
          S3_BUCKET: youtube-clone-backups
        run: |
          # Delete backups older than 90 days
          CUTOFF_DATE=$(date -d '90 days ago' +%Y-%m-%d)
          aws s3 ls s3://$S3_BUCKET/database/ | \
            awk '{print $4}' | \
            while read file; do
              FILE_DATE=$(echo $file | grep -oP '\d{8}' | head -1)
              if [[ $FILE_DATE < ${CUTOFF_DATE//[-]/} ]]; then
                echo "Deleting old backup: $file"
                aws s3 rm s3://$S3_BUCKET/database/$file
              fi
            done
